{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44455aad-0d50-4a8d-816a-6551e2e91035",
   "metadata": {},
   "source": [
    "### [Index of /reimers/sentence-transformers/v0.2/](https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7379389e-7a15-4dc7-aed6-e0b02f24c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# default is in ~/.cache\n",
    "# os.environ['HF_HOME'] = '/home/jovyan/cache/'\n",
    "# os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba9b56-2d4c-4864-ae2c-aad98feefae9",
   "metadata": {},
   "source": [
    "### reload from cache snapshot (need to locate the config.json location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76db61a-6225-4a60-9464-a870afb57865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL='thenlper/gte-small'\n",
    "# MODEL='/home/jovyan/cache/hub/models--thenlper--gte-small/snapshots/17e1f347d17fe144873b1201da91788898c639cd'\n",
    "# gte_model = SentenceTransformer(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531412dd-62c1-4064-b71c-5930c024d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb1c98b-2465-4107-97c1-571188ff0bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 25, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('gte-small')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e89a3f-f892-4428-bc45-4254ab46a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4dc1b0-c758-4dda-b446-6b82e6b12ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MODEL = 'all-mpneimport os\n",
    "# os.environ['HF_HOME'] = '/blabla/cache/'t-base-v2'\n",
    "# MODEL = r'../all-MiniLM-L6-v2'\n",
    "MODEL='thenlper/gte-small'\n",
    "# MODEL = 'all-MiniLM-L12-v2\n",
    "\n",
    "\n",
    "################# LOAD SENTENCE TRANSFORMER MODEL ###########################\n",
    "# Load the embedding model and tokenizer manually\n",
    "\n",
    "word_embedding_model = models.Transformer(MODEL)\n",
    "\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "# Assemble the sentence transformer model\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "MAX_SEQ_LENGTH = 25\n",
    "\n",
    "model[0].max_seq_length = MAX_SEQ_LENGTH\n",
    "model[0].tokenizer.max_seq_length = MAX_SEQ_LENGTH\n",
    "model[0].do_lower_case = True\n",
    "model[1].pooling_mode_cls_token=True\n",
    "model[1].pooling_mode_mean_tokens=False\n",
    "model[1].pooling_mode_max_tokens=False\n",
    "model[1].pooling_mode_mean_sqrt_len_tokens=False\n",
    "model[1].pooling_mode_weightedmean_tokens=False\n",
    "model[1].pooling_mode_lasttoken=False\n",
    "\n",
    "print(f\"{model=}\")\n",
    "\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# model = SentenceTransformer('../all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "# Save the model locally\n",
    "model.save(r'../gte-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9814f4f-7651-4767-ba7a-62b16f016e9a",
   "metadata": {},
   "source": [
    "### Using Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d88e05-7036-4307-8a56-f8d14405b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(r',,/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained(r'../all-MiniLM-L6-v2')\n",
    "\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "print(f\"{encoded_input=}\")\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    print(f\"{model_output['last_hidden_state'].shape=}\")\n",
    "    print(f\"{model_output['pooler_output'].shape=}\")\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "print(f\"{sentence_embeddings.shape=}\")\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c040a-6f0a-451b-b73d-bdd03250ec1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
